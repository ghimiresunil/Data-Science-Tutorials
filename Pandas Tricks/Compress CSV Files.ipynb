{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1a86e4d",
   "metadata": {},
   "source": [
    "## Compress your data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4697b734",
   "metadata": {},
   "source": [
    "When working with data you often come accross CSV files. The great thing about CSV files is that they are human readable. The bad thing is that they are not very space efficient. My experience is that the 'human readable' benefit is only a marginal benefit when working with that file for the first time.\n",
    "\n",
    "A nice CSV feature of Pandas is to store your data in a compressed way using the compression parameter. Out of the box Pandas can us zip/gzip, bz2, and xz compression when storing a DataFrame. As we are generally using the '.csv.gz' as an extention, Pandas can automatically infer the compression, therefore, we can omit the compression parameter.\n",
    "\n",
    "As we are compressing the data, it takes a bit more effort to store the data. Obviously, the compressed file is not human readable anymore. Under the hood, Pandas uses the gzip, bzip2, and the xz library and streams the text lines to the compressed file. The most efficient is bzip2, which reduces the size to one third of the original size while taking three times longer.\n",
    "\n",
    "Writing the data line by line is of course not very efficient and as we loose the \"benefit\" of human readability anyhow, we could also store it as Parquet. Parquet is a column format and highly optimized for reading, i.e. writing takes a bit more effort. Still, compared to a method that stores line by line, Parquet is blazingly fast and until now, I have not yet seen any real downsides of using it.\n",
    "\n",
    "Parquet is by far my favorite format and I highly recommend it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "941b8da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from pathlib import Path\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "n_rows, n_cols = 100_100, 100\n",
    "\n",
    "# Lets generate some random data\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    rng.integers(0,1000, size=(n_rows, n_cols)),\n",
    "    columns=[str(x) for x in np.arange(n_cols)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c47fd27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filesize(f: Path) -> str:\n",
    "    file_size = f.stat().st_size\n",
    "    for unit in ['','K','M','G','T']:\n",
    "        if file_size < 1024:\n",
    "            return f\"{file_size:3.1f}{unit}B\"\n",
    "        file_size /= 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbbcfc8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file size: 37.7MB\n",
      "CPU times: user 2.7 s, sys: 82.9 ms, total: 2.78 s\n",
      "Wall time: 2.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "large_file = Path('large_file.csv')\n",
    "df.to_csv(large_file)\n",
    "print(f'CSV file size: {get_filesize(large_file)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ddb01a",
   "metadata": {},
   "source": [
    "## Using gzip compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e610d52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gzip_file = Path('gzipped_file.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a8dd4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.4 s, sys: 55.3 ms, total: 10.5 s\n",
      "Wall time: 10.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.to_csv(gzip_file, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74fc7a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GZ CSV file size: 15.7MB\n"
     ]
    }
   ],
   "source": [
    "print(f'GZ CSV file size: {get_filesize(gzip_file)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515115ed",
   "metadata": {},
   "source": [
    "The default option for compression is 'infer' which detects which type of compression is used from the extention. Therefore, we only need to supply the .gz extentions and it will automatically gzip the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e66a0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bzip_file = Path('bzipped_file.csv.bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce7e34b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.02 s, sys: 15.8 ms, total: 6.04 s\n",
      "Wall time: 6.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.to_csv(bzip_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64045b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BZ2 CSV file size: 12.7MB\n"
     ]
    }
   ],
   "source": [
    "print(f'BZ2 CSV file size: {get_filesize(bzip_file)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9fde2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "xzip_file = Path('xzipped_file.csv.xz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9aed14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 47.6 s, sys: 144 ms, total: 47.8 s\n",
      "Wall time: 47.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.to_csv(xzip_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc78b3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XZ CSV file size: 13.9MB\n"
     ]
    }
   ],
   "source": [
    "print(f'XZ CSV file size: {get_filesize(xzip_file)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2cbef5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_file = Path('parquet_file.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "254df175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 530 ms, sys: 76 ms, total: 606 ms\n",
      "Wall time: 388 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.to_parquet(parquet_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84c295b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet file size: 12.4MB\n"
     ]
    }
   ],
   "source": [
    "print(f'Parquet file size: {get_filesize(parquet_file)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
